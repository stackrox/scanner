#! circleci config validate
version: 2.1

defaultImage: &defaultImage
  image: quay.io/cgorman1/apollo-ci:0.3.18
  auth:
    username: $QUAY_CGORMAN1_RO_USER
    password: $QUAY_CGORMAN1_RO_PASSWORD

defaultWorkingDirectory: &defaultWorkingDirectory '/go/src/github.com/stackrox/scanner'

defaults: &defaults
  docker:
    - *defaultImage
  working_directory: /go/src/github.com/stackrox/scanner

runOnAllTags: &runOnAllTags
  filters:
    tags:
      only: /.*/

runOnAllTagsWithQuayPullCtx: &runOnAllTagsWithQuayPullCtx
  <<: *runOnAllTags
  context: quay-cgorman1-readonly

runOnAllTagsWithRedHatCtx: &runOnAllTagsWithRedHatCtx
  <<: *runOnAllTags
  context:
  - redhat-developer-account-login
  - quay-cgorman1-readonly

# https://circleci.com/developer/orbs/orb/circleci/slack
orbs:
  slack: circleci/slack@4.4.2

slackTemplateTestFailure: &slackTemplateTestFailure
  custom: |
     {
       "text": "CircleCI job failed.",
       "blocks": [
         {
           "type": "header",
           "text": {
             "type": "plain_text",
             "text": "Job Failed. :red_circle:",
             "emoji": true
           }
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Job*: ${CIRCLE_JOB}"
             }
           ]
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Project*: $CIRCLE_PROJECT_REPONAME"
             },
             {
               "type": "mrkdwn",
               "text": "*Branch*: $CIRCLE_BRANCH"
             }
           ]
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Mentions*: $SLACK_PARAM_MENTIONS"
             }
           ]
         },
         {
           "type": "actions",
           "elements": [
             {
               "type": "button",
               "text": {
                 "type": "plain_text",
                 "text": "View Job"
               },
               "url": "${CIRCLE_BUILD_URL}"
             }
           ]
         }
       ]
     }

commands:
  check-on-master-or-tag:
    description: Run on master or tags only
    steps:
      - run:
          name: Determine whether to run step
          command: |
            if [[ "${CIRCLE_BRANCH}" == "master" || -n "${CIRCLE_TAG}" ]]; then
              echo "On master or tag, running the step"
            else
              echo "Not on master or tag, halting step"
              circleci step halt
            fi

  check-label-to-run:
    description: Run on master, but skip on PRs and tags unless the given label is provided
    parameters:
      label:
        type: string
      runOnMaster:
        type: boolean
        default: true
      runOnTag:
        type: boolean
        default: false
    steps:
      - run:
          name: Determine whether to run step
          command: |
            set +e
            if [[ "${CIRCLE_BRANCH}" == "master" ]]; then
              if [[ "<< parameters.runOnMaster >>" == "true" ]]; then
                echo "On master, running the step"
              else
                echo "On master, but not running the step"
                circleci step halt
              fi
            elif [[ -n "${CIRCLE_TAG}" ]]; then
              if [[ "<< parameters.runOnTag >>" == "true" ]]; then
                echo "On tag ${CIRCLE_TAG} with runOnTag set to true, running the step"
              else
                echo "On tag ${CIRCLE_TAG} with runOnTag set to false, halting the step"
                circleci step halt
              fi
            else
              .circleci/pr_has_label.sh "<< parameters.label >>"
              if [[ $? -eq 1 ]]; then
                echo "Skipping tests because we're on a PR. Apply the << parameters.label >> label to your PR if you want to run them."
                circleci step halt
              fi
            fi

  wait-for-scanner-and-pf:
    description: Wait for the scanner pod to meet the given condition, and port-forward
    parameters:
      condition:
        type: string
      sleep-after-condition-met:
        type: integer
        default: 0
    steps:
      - run:
          name: Wait for the pod to be << parameters.condition >>, and port-forward
          command: |
            sleep 5
            kubectl -n stackrox get pod
            POD="$(kubectl -n stackrox get pod -o jsonpath='{.items[?(@.metadata.labels.app=="scanner")].metadata.name}')"
            [[ -n "${POD}" ]]
            kubectl -n stackrox wait "--for=condition=<< parameters.condition >>" "pod/${POD}" --timeout=3m
            sleep << parameters.sleep-after-condition-met >>
            kubectl -n stackrox get pod

            success=0
            for i in $(seq 1 10); do
              nohup kubectl port-forward -n stackrox "${POD}" "8080:8080" & # Legacy clairify endpoint
              nohup kubectl port-forward -n stackrox "${POD}" "8443:8443" & # gRPC endpoint
              curl --retry 12 --retry-connrefused -4 --retry-delay 5 --retry-max-time 60 -sk 'https://localhost:8080/clairify/ping' || touch FAIL
              curl --retry 12 --retry-connrefused -4 --retry-delay 5 --retry-max-time 60 -skf 'https://localhost:8443/v1/ping' || touch FAIL
              if [[ ! -f FAIL ]]; then
                success=1
                break
              fi
              echo "Port-forwarding failed."
              cat nohup.out || true
              rm nohup.out || true
              rm FAIL || true
              pkill kubectl || true
              sleep 5
            done

            [[ "${success}" -gt 0 ]]

  scanner-db-pf:
    description: Port-forward the scanner db
    steps:
      - run:
          name: Port-forward
          command: |
            sleep 5
            kubectl -n stackrox get pod
            POD="$(kubectl -n stackrox get pod -o jsonpath='{.items[?(@.metadata.labels.app=="scanner-db")].metadata.name}')"
            [[ -n "${POD}" ]]
            kubectl -n stackrox wait "--for=condition=Ready" "pod/${POD}" --timeout=10m
            nohup kubectl port-forward -n stackrox "${POD}" "5432:5432" & # PostgreSQL endpoint.
            sleep 10

  setup-gcp:
    description: Set up GCP service account and configure gcloud
    parameters:
      service-account-env:
        type: string
        default: GOOGLE_SA_CIRCLECI_SCANNER
    steps:
      - run:
          name: Configure GCP service account and gcloud
          command: |
            cci-export GOOGLE_APPLICATION_CREDENTIALS /tmp/gcp.json
            echo "${<< parameters.service-account-env >>}" > "${GOOGLE_APPLICATION_CREDENTIALS}"
            chmod 0600 "${GOOGLE_APPLICATION_CREDENTIALS}"
            gcloud auth activate-service-account --key-file "${GOOGLE_APPLICATION_CREDENTIALS}"
            gcloud auth list
            gcloud auth configure-docker
            gcloud config set project stackrox-ci
            gcloud config set core/disable_prompts True

  create-gke:
    parameters:
      wait:
        type: boolean
        default: true

    steps:
      - run:
          name: Create GKE cluster
          command: |
            source .circleci/create-cluster.sh && create-cluster
            <<# parameters.wait >>
            wait-for-cluster
            <</ parameters.wait >>

  teardown-gke:
    steps:
      - run:
          name: Tear down GKE cluster
          command: |
            [[ -n "$CLUSTER_NAME" ]]
            gcloud container clusters delete "$CLUSTER_NAME" --async

          when: always

  provision-gke-cluster:
    parameters:
      cluster-id:
        type: string
      num-nodes:
        type: integer
        default: 1

    steps:
      - setup-gcp
      - run:
          name: Assign environment variables
          command: |
            CLUSTER_NAME="stackrox-scanner-ci-<< parameters.cluster-id >>-${CIRCLE_BUILD_NUM}"
            cci-export CLUSTER_NAME "$CLUSTER_NAME"
            echo "Assigned cluster name is $CLUSTER_NAME"

            NUM_NODES="<< parameters.num-nodes >>"
            cci-export NUM_NODES "$NUM_NODES"
            echo "Number of nodes for cluster is $NUM_NODES"

      - create-gke:
          wait: false

      - run:
          name: Save cluster config
          command: |
            CONFIG_DIR="/tmp/.ci-clusters/<< parameters.cluster-id >>"
            mkdir -p "$CONFIG_DIR"
            echo "$CLUSTER_NAME" >>"${CONFIG_DIR}/name"
            gcloud config get-value compute/zone >>"${CONFIG_DIR}/zone"

      - run:
          name: Tear down cluster upon failure
          command: |
            gcloud container clusters delete "$CLUSTER_NAME" --async
          when: on_fail

      - persist_to_workspace:
          root: /tmp
          paths:
            - .ci-clusters/<< parameters.cluster-id >>

  attach-gke-cluster:
    parameters:
      cluster-id:
        type: string

    steps:
      - run:
          name: Restore config for << parameters.cluster-id >> cluster
          command: |
            CONFIG_DIR="/tmp/.ci-clusters/<< parameters.cluster-id >>"
            CLUSTER_NAME="$(cat "${CONFIG_DIR}/name")"
            [[ -n "$CLUSTER_NAME" ]]
            ZONE="$(cat "${CONFIG_DIR}/zone")"
            [[ -n "$ZONE" ]]
            gcloud config set compute/zone "$ZONE"
            cmd=(gcloud container clusters get-credentials --project stackrox-ci --zone "$ZONE" "$CLUSTER_NAME")
            "${cmd[@]}"
            echo "Restored config for cluster ${CLUSTER_NAME}"
            cci-export CLUSTER_NAME "$CLUSTER_NAME"
            echo
            echo "Run the following command to attach to the cluster:"
            echo
            printf " %q" "${cmd[@]}"
            echo

  build-and-push-image:
    parameters:
      make-image-target:
        type: string

    steps:
      - checkout
      - setup_remote_docker
      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Pull definitions dumps
          command: |
            if .circleci/pr_has_label.sh "generate-dumps-on-pr"; [[ $? -eq 1 ]]; then
              echo "Label generate-dumps-on-pr not set. Pulling dumps from GCS bucket"
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/pg-definitions.sql.gz image/db/dump/definitions.sql.gz
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/nvd-definitions.zip /tmp/nvd-definitions.zip
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/k8s-definitions.zip /tmp/k8s-definitions.zip
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/repo2cpe.zip /tmp/repo2cpe.zip
            else
              cp /tmp/postgres/pg-definitions.sql.gz image/db/dump/definitions.sql.gz
              zip /tmp/genesis-dump/dump.zip 'nvd/*' --copy --out /tmp/nvd-definitions.zip
              zip /tmp/genesis-dump/dump.zip 'k8s/*' --copy --out /tmp/k8s-definitions.zip
              zip /tmp/genesis-dump/dump.zip 'rhelv2/repository-to-cpe.json' --copy --out /tmp/repo2cpe.zip
            fi

            unzip -d image/scanner/dump /tmp/nvd-definitions.zip
            unzip -d image/scanner/dump /tmp/k8s-definitions.zip
            unzip -d image/scanner/dump /tmp/repo2cpe.zip

      - install-ossls

      - run:
          name: Build images
          command: make << parameters.make-image-target >>

      - run:
          name: Ensure image is not dirty
          command: git diff --exit-code HEAD

      - run:
          name: Push images
          command: |
            tag="$(make --quiet --no-print-directory tag)"
            scanner_image_name="scanner"
            db_image_name="scanner-db"

            gcr_scanner_image="us.gcr.io/stackrox-ci/${scanner_image_name}:${tag}"
            gcr_db_image="us.gcr.io/stackrox-ci/${db_image_name}:${tag}"

            ./scripts/push-as-manifest-list.sh "${gcr_scanner_image}"
            ./scripts/push-as-manifest-list.sh "${gcr_db_image}"

            # Retag for docker.io
            docker login -u "$DOCKER_IO_PUSH_USERNAME" -p "$DOCKER_IO_PUSH_PASSWORD" docker.io

            dockerhub_scanner_image="stackrox/${scanner_image_name}:${tag}"
            docker tag "${gcr_scanner_image}" "${dockerhub_scanner_image}"
            ./scripts/push-as-manifest-list.sh "${dockerhub_scanner_image}"

            # Retag as -rhel for historical reasons
            dockerhub_scanner_rhel_image="stackrox/${scanner_image_name}-rhel:${tag}"
            docker tag "${dockerhub_scanner_image}" "${dockerhub_scanner_rhel_image}"
            ./scripts/push-as-manifest-list.sh "${dockerhub_scanner_rhel_image}"

            dockerhub_db_image="stackrox/${db_image_name}:${tag}"
            docker tag "${gcr_db_image}" "${dockerhub_db_image}"
            ./scripts/push-as-manifest-list.sh "${dockerhub_db_image}"

            # Retag as -rhel for historical reasons
            dockerhub_db_rhel_image="stackrox/${db_image_name}-rhel:${tag}"
            docker tag "${dockerhub_db_image}" "${dockerhub_db_rhel_image}"
            ./scripts/push-as-manifest-list.sh "${dockerhub_db_rhel_image}"

            # Retag for quay.io

            docker login -u "$QUAY_CGORMAN1_RW_USER" -p "$QUAY_CGORMAN1_RW_PASSWORD" quay.io

            QUAY_REPO="cgorman1"
            quay_scanner_image="quay.io/$QUAY_REPO/${scanner_image_name}:${tag}"
            docker tag "${gcr_scanner_image}" "${quay_scanner_image}"
            ./scripts/push-as-manifest-list.sh "${quay_scanner_image}"

            # Retag as -rhel for historical reasons
            quay_scanner_rhel_image="quay.io/$QUAY_REPO/${scanner_image_name}-rhel:${tag}"
            docker tag "${quay_scanner_image}" "${quay_scanner_rhel_image}"
            ./scripts/push-as-manifest-list.sh "${quay_scanner_rhel_image}"

            quay_db_image="quay.io/$QUAY_REPO/${db_image_name}:${tag}"
            docker tag "${gcr_db_image}" "${quay_db_image}"
            ./scripts/push-as-manifest-list.sh "${quay_db_image}"

            quay_db_rhel_image="quay.io/$QUAY_REPO/${db_image_name}-rhel:${tag}"
            docker tag "${quay_db_image}" "${quay_db_rhel_image}"
            ./scripts/push-as-manifest-list.sh "${quay_db_rhel_image}"

            if [[ -n "$CIRCLE_TAG" ]]; then
                docker login -u "$STACKROX_IO_PUSH_USERNAME" -p "$STACKROX_IO_PUSH_PASSWORD" stackrox.io

                stackrox_io_scanner_image="stackrox.io/${scanner_image_name}:${tag}"
                stackrox_io_scanner_db_image="stackrox.io/${db_image_name}:${tag}"

                docker tag "${gcr_scanner_image}" "${stackrox_io_scanner_image}"
                docker tag "${gcr_db_image}" "${stackrox_io_scanner_db_image}"

                ./scripts/push-as-manifest-list.sh "${stackrox_io_scanner_image}"
                ./scripts/push-as-manifest-list.sh "${stackrox_io_scanner_db_image}"

                # Retag as -rhel for historical reasons
                stackrox_io_scanner_rhel_image="stackrox.io/${scanner_image_name}-rhel:${tag}"
                stackrox_io_scanner_db_rhel_image="stackrox.io/${db_image_name}-rhel:${tag}"

                docker tag "${stackrox_io_scanner_image}" "${stackrox_io_scanner_rhel_image}"
                docker tag "${stackrox_io_scanner_db_image}" "${stackrox_io_scanner_db_rhel_image}"

                ./scripts/push-as-manifest-list.sh "${stackrox_io_scanner_rhel_image}"
                ./scripts/push-as-manifest-list.sh "${stackrox_io_scanner_db_rhel_image}"
            fi
  run-e2e-tests:
    parameters:
      cluster-id:
        type: string

    steps:
      - checkout
      - setup_remote_docker
      - setup-gcp

      - attach_workspace:
          at: /tmp

      - attach-gke-cluster:
          cluster-id: << parameters.cluster-id >>

      - run:
          name: Deploy into the cluster
          command: |
            make deploy

      - wait-for-scanner-and-pf:
          condition: Ready

      - run:
          name: Run sanity tests
          no_output_timeout: 20m
          command: |
            make e2e-tests

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - fetch-and-upload-scanner-metrics

      - run-db-integration-tests

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - store_artifacts:
          path: /tmp/k8s-service-logs
          destination: k8s-service-logs-<< parameters.cluster-id >>

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - run:
          name: Verify that StackRox service logs contain no suspicious entries
          command: |
            if [[ ! -d "/tmp/k8s-service-logs/stackrox" ]]; then
              echo >&2 "StackRox logs were not collected. (Use collect: true or collectK8sLogs.)"
              exit 1
            fi
            logs=$(ls /tmp/k8s-service-logs/stackrox/*.log)
            filtered=$(ls ${logs} | grep -v "previous.log" || true)
            if [[ -n "${filtered}" ]]; then
                if ! scripts/ci/logcheck/check.sh ${filtered}; then
                    echo >&2 "Found at least one suspicious log file entry."
                    exit 1
                fi
            fi
          when: always

      - teardown-gke

  run-db-integration-tests:
    steps:
      - scanner-db-pf
      - run:
          name: Run db integration tests
          command: make db-integration-tests

  run-scale-tests:
    parameters:
      cluster-id:
        type: string

    steps:
      - checkout
      - check-label-to-run:
          label: scale-tests
          runOnMaster: false
      - setup_remote_docker
      - setup-gcp

      - attach_workspace:
          at: /tmp

      - attach-gke-cluster:
          cluster-id: << parameters.cluster-id >>

      - run:
          name: Deploy into the cluster
          command: |
            cci-export LOGLEVEL "INFO"
            make deploy

      - wait-for-scanner-and-pf:
          condition: Ready

      - run:
          name: Run scale tests and collect profile
          no_output_timeout: 20m
          command: make scale-tests

      - store_artifacts:
          path: /tmp/pprof.zip
          destination: pprof.zip

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - fetch-and-upload-scanner-metrics

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - store_artifacts:
          path: /tmp/k8s-service-logs
          destination: k8s-service-logs-<< parameters.cluster-id >>

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - run:
          name: Verify that StackRox service logs contain no suspicious entries
          command: |
            if [[ ! -d "/tmp/k8s-service-logs/stackrox" ]]; then
              echo >&2 "StackRox logs were not collected. (Use collect: true or collectK8sLogs.)"
              exit 1
            fi
            logs=$(ls /tmp/k8s-service-logs/stackrox/*.log)
            filtered=$(ls ${logs} | grep -v "previous.log" || true)
            if [[ -n "${filtered}" ]]; then
                if ! scripts/ci/logcheck/check.sh ${filtered}; then
                    echo >&2 "Found at least one suspicious log file entry."
                    exit 1
                fi
            fi
          when: always

      - teardown-gke

  fetch-and-upload-scanner-metrics:
    steps:
      - run:
          name: Portforward and curl scanner metrics
          command: |
            kubectl -n stackrox port-forward deploy/scanner 9090:9090 1>/dev/null 2>&1 &
            sleep 5
            mkdir -p /tmp/metrics
            curl localhost:9090/metrics > /tmp/metrics/metrics.prom
      - store_artifacts:
          path: /tmp/metrics
          destination: metrics

  install-ossls:
    steps:
    - run:
        name: Install ossls
        working_directory: /tmp
        command: |
          wget --quiet https://github.com/gruntwork-io/fetch/releases/download/v0.3.5/fetch_linux_amd64
          sudo install fetch_linux_amd64 /usr/bin/fetch
          export GITHUB_OAUTH_TOKEN="$GITHUB_TOKEN"
          fetch --repo="https://github.com/stackrox/ossls" --tag="0.10.1" --release-asset="ossls_linux_amd64" .
          sudo install ossls_linux_amd64 /usr/bin/ossls
          ossls version

jobs:
  unit-tests:
    <<: *defaults
    steps:
      - checkout

      - run:
          name: Install dependencies
          command: make deps

      - run:
          name: Run unit tests
          command: make unit-tests

  style-checks:
    <<: *defaults
    steps:
      - checkout

      - run:
          name: Install dependencies
          command: make deps

      - run:
          name: Run style checks
          command: make style

  generate-genesis-dump:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true
      - run:
          name: Build updater, and persist to workspace
          command: |
            make build-updater
            mkdir -p /tmp/updater-bin
            cp ./bin/updater /tmp/updater-bin/

      - run:
          name: Generate the genesis dump
          command: |
            mkdir -p /tmp/genesis-dump
            ./bin/updater generate-dump --out-file /tmp/genesis-dump/dump.zip
            ls -lrt /tmp/genesis-dump

      - run:
          name: Print some stats
          command: |
            ./bin/updater print-stats /tmp/genesis-dump/dump.zip

      - store_artifacts:
          path: /tmp/genesis-dump/dump.zip
          destination: genesis-dump.zip

      - persist_to_workspace:
          root: /tmp
          paths:
            - genesis-dump
            - updater-bin

  create-postgres-dump-from-genesis-dump:
    docker:
      - *defaultImage
      - image: postgres:12.0-alpine
    working_directory: *defaultWorkingDirectory
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true
      - setup_remote_docker
      - attach_workspace:
          at: /tmp

      - run:
          name: Restore updater bin
          command: |
            cp /tmp/updater-bin/updater ./bin/

      - run:
          name: Load vuln contents into postgres
          command: |
            ./bin/updater load-dump --postgres-host 127.0.0.1 --postgres-port 5432 --dump-file /tmp/genesis-dump/dump.zip

      - run:
          name: Take a PG dump
          command: |
            mkdir /tmp/postgres
            pg_dump -U postgres postgres://127.0.0.1:5432 > /tmp/postgres/pg-definitions.sql
            gzip --best /tmp/postgres/pg-definitions.sql

      - store_artifacts:
          path: /tmp/postgres/pg-definitions.sql.gz
          destination: pg-definitions.sql.gz

      - persist_to_workspace:
          root: /tmp
          paths:
            - postgres

      - check-on-master-or-tag
      - setup-gcp
      - run:
          name: Upload PG dump to Google Storage
          command: |
            echo "On master or tag, uploading pg dump result to GCS"
            gsutil cp /tmp/postgres/pg-definitions.sql.gz gs://stackrox-scanner-ci-vuln-dump

  upload-dumps-for-embedding-into-image:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: false

      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Generate dumps
          command: |
            mkdir -p /tmp/vuln-dump
            zip /tmp/genesis-dump/dump.zip 'nvd/*' --copy --out /tmp/vuln-dump/nvd-definitions.zip
            zip /tmp/genesis-dump/dump.zip 'k8s/*' --copy --out /tmp/vuln-dump/k8s-definitions.zip
            zip /tmp/genesis-dump/dump.zip 'rhelv2/repository-to-cpe.json' --copy --out /tmp/vuln-dump/repo2cpe.zip

      - persist_to_workspace:
          root: /tmp
          paths:
            - vuln-dump

      - run:
          name: Upload to Google Storage
          command: |
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/nvd-definitions.zip gs://stackrox-scanner-ci-vuln-dump
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/k8s-definitions.zip gs://stackrox-scanner-ci-vuln-dump
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/repo2cpe.zip gs://stackrox-scanner-ci-vuln-dump

  # Copy definitions files to be available in the publicly-accessible bucket for embedding in the downstream builds on
  # the Red Hat infrastructure. See usage in distgit/containers/rhacs-scanner/pre-build-script
  # and in distgit/containers/rhacs-scanner-db/pre-build-script
  # in branches of https://code.engineering.redhat.com/gerrit/gitweb?p=rhacs.git;a=summary
  upload-dumps-for-downstream-builds:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
      - setup-gcp
      - attach_workspace:
          at: /tmp
      - run:
          name: Upload dumps to Google Storage
          command: |
            set -x
            if [[ "${CIRCLE_BRANCH}" == "master" ]]; then
              # On master branch we upload production dumps therefore we use the latest tag as a version.
              # The following command will output only the latest tag like `2.20.0` but not `2.20.0-3-g74ff9abf69-dirty`.
              scanner_version="$(git describe --tags --abbrev=0)"
            else
              # For other cases (e.g. PR with the expected label) use the tag that makefile returns to avoid overwriting
              # the production dumps.
              scanner_version="$(make --quiet --no-print-directory tag)"
            fi
            destination="gs://definitions.stackrox.io/scanner-data/${scanner_version}/"
            gsutil cp /tmp/vuln-dump/nvd-definitions.zip "$destination"
            gsutil cp /tmp/vuln-dump/k8s-definitions.zip "$destination"
            gsutil cp /tmp/vuln-dump/repo2cpe.zip "$destination"
            gsutil cp /tmp/postgres/pg-definitions.sql.gz "$destination"

  create-diff-dumps:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: false
      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Restore updater bin
          command: |
            cp /tmp/updater-bin/updater ./bin/

      - run:
          name: Create diff for each manifest
          command: |
            mkdir -p /tmp/diff-dumps
            idx=-1
            while IFS=$'\t' read -r dumploc timestamp config; do
              idx=$((idx+1))
              dump_file_name="${dumploc##*/}"
              echo "Pulling genesis dump from ${dumploc}"
              gsutil cp "${dumploc}" .
              timestamp_in_zip="$(unzip -p "${dump_file_name}" manifest.json | jq -r '.until')"
              echo "Got timestamps -- from zip: ${timestamp_in_zip}; from manifest: ${timestamp}"
              [[ "${timestamp_in_zip}" == "${timestamp}" ]] # Assertion on the manifest contents
              ./bin/updater diff-dumps --base-dump "${dump_file_name}" --head-dump /tmp/genesis-dump/dump.zip --config "${config}" --out-file "/tmp/diff-dumps/dump${idx}/diff.zip"
            done < <(jq -r '.knownGenesisDumps | .[]| [.dumpLocationInGS, .timestamp, (.config // empty | tostring)] | @tsv' < image/scanner/dump/genesis_manifests.json)
            du -d 2 -kh "/tmp/diff-dumps"

      - persist_to_workspace:
          root: /tmp
          paths:
            - diff-dumps

      - store_artifacts:
          path: /tmp/diff-dumps

  upload-diff-dumps-and-offline-dumps:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: false
      - setup-gcp:
          service-account-env: GOOGLE_SA_STACKROX_HUB_VULN_DUMP_UPLOADER
      - attach_workspace:
          at: /tmp

      - run:
          name: Upload each diff dump to the prod bucket
          command: |
            idx=-1
            while IFS=$'\t' read -r diffloc; do
              idx=$((idx+1))
              expected_zip_file_loc="/tmp/diff-dumps/dump${idx}/diff.zip"
              [[ -f "${expected_zip_file_loc}" ]]
              if [[ -z "${diffloc}" ]]; then
                continue
              fi
              echo "Found file at ${expected_zip_file_loc}"
              du -skh "${expected_zip_file_loc}"
              cmd=()
              if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
                cmd+=(echo "Would do")
              fi
              "${cmd[@]}" gsutil cp "${expected_zip_file_loc}" "${diffloc}"
            done < <(jq -r '.knownGenesisDumps | .[]| [.diffLocation] | @tsv' < image/scanner/dump/genesis_manifests.json)

      - run:
          name: Generate offline dump
          command: |
            mkdir -p /tmp/offline-dump

            # Fetch the scanner dump which is marked as the base for offline dumps.
            # For offline dumps, we just use one base (the oldest base which is in a version of scanner still supported)
            # for simplicity.
            offline_dumps="$(jq '.knownGenesisDumps | map(.baseForOfflineDumps == true) | indices(true)' < image/scanner/dump/genesis_manifests.json)"
            echo "Got offline dumps list: ${offline_dumps}"
            [[ "$(echo "${offline_dumps}" | jq 'length')" -eq 1 ]]
            offline_diff_location="/tmp/diff-dumps/dump$(echo "${offline_dumps}" | jq -r '.[0]')/diff.zip"
            cp "${offline_diff_location}" /tmp/offline-dump/scanner-defs.zip

            # Prepare k8s and istio dump
            mkdir -p /tmp/scratch
            gsutil cp -r gs://definitions.stackrox.io/cve/* /tmp/scratch/
            cd /tmp/scratch
            zip -r /tmp/offline-dump/k8s-istio.zip *

            cd /tmp/offline-dump
            zip scanner-vuln-updates.zip scanner-defs.zip k8s-istio.zip
            du -skh scanner-vuln-updates.zip
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp scanner-vuln-updates.zip gs://sr-roxc/scanner/scanner-vuln-updates.zip

      - setup-gcp:
          service-account-env: GCP_SERVICE_ACCOUNT_CREDS

      - run:
          name: Push offline dump to a public bucket
          command: |
            cd /tmp/offline-dump
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp scanner-vuln-updates.zip gs://scanner-support-public/offline/v1/scanner-vuln-updates.zip

  build:
    <<: *defaults
    steps:
      - build-and-push-image:
          make-image-target: image

  provision-cluster:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - provision-gke-cluster:
          cluster-id: rhel

  provision-scale-cluster:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: scale-tests
          runOnMaster: false
      - setup_remote_docker
      - provision-gke-cluster:
          cluster-id: rhel-scale

  e2e-tests:
    <<: *defaults
    steps:
      - run-e2e-tests:
          cluster-id: rhel

  scale-tests:
    <<: *defaults
    steps:
      - run-scale-tests:
          cluster-id: rhel-scale

  sanity-check-vuln-updates:
    <<: *defaults
    steps:
      - checkout
      - setup-gcp:
          service-account-env: GOOGLE_SA_STACKROX_HUB_VULN_DUMP_UPLOADER
      - run:
          name: Check scanner vulnerability updates
          command: ./tests/sanity-check-vuln-updates.sh
      - store_artifacts:
          path: /tmp/ROX-7271
      - slack/notify:
          branch_pattern: master
          channel: oncall
          event: fail
          ignore_errors: false
          mentions: "@scanner-defs-oncall,@shane"
          <<: *slackTemplateTestFailure

workflows:
  version: 2

  update-dumps-hourly:
    triggers:
      - schedule:
          cron: "0 * * * *"
          filters:
            branches:
              only: master

    jobs:
      - generate-genesis-dump:
          <<: *runOnAllTagsWithQuayPullCtx
      - create-postgres-dump-from-genesis-dump:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - create-diff-dumps:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - upload-dumps-for-embedding-into-image:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - upload-diff-dumps-and-offline-dumps:
          <<: *runOnAllTags
          context:
            - quay-cgorman1-readonly
            - scanner-support
          requires:
            - create-diff-dumps
      - upload-dumps-for-downstream-builds:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - create-postgres-dump-from-genesis-dump
            - upload-dumps-for-embedding-into-image
      - unit-tests:
          <<: *runOnAllTagsWithQuayPullCtx
      - style-checks:
          <<: *runOnAllTagsWithQuayPullCtx
      - build:
          <<: *runOnAllTags
          context:
            - docker-io-and-stackrox-io-push
            - quay-cgorman1-readwrite
            - quay-cgorman1-readonly
          requires:
            - create-postgres-dump-from-genesis-dump
            - upload-dumps-for-embedding-into-image
      - provision-cluster:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - create-postgres-dump-from-genesis-dump
      - e2e-tests:
          <<: *runOnAllTagsWithRedHatCtx
          requires:
            - build
            - provision-cluster

  sanity-check-vuln-updates-scheduled:
    triggers:
      - schedule:
          cron: "35 0,4,8,12,16,20 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - sanity-check-vuln-updates:
          context:
          - quay-cgorman1-readonly
          - com-slack-srox

  build:
    jobs:
    - generate-genesis-dump:
        <<: *runOnAllTagsWithQuayPullCtx
    - create-postgres-dump-from-genesis-dump:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - create-diff-dumps:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - upload-dumps-for-embedding-into-image:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - upload-diff-dumps-and-offline-dumps:
        <<: *runOnAllTags
        context:
          - quay-cgorman1-readonly
          - scanner-support
        requires:
          - create-diff-dumps
    - upload-dumps-for-downstream-builds:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - create-postgres-dump-from-genesis-dump
          - upload-dumps-for-embedding-into-image
    - unit-tests:
        <<: *runOnAllTagsWithQuayPullCtx
    - style-checks:
        <<: *runOnAllTagsWithQuayPullCtx
    - build:
        <<: *runOnAllTags
        context:
          - docker-io-and-stackrox-io-push
          - quay-cgorman1-readonly
          - quay-cgorman1-readwrite
        requires:
          - create-postgres-dump-from-genesis-dump
          - upload-dumps-for-embedding-into-image
    - provision-cluster:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - create-postgres-dump-from-genesis-dump
    - e2e-tests:
        <<: *runOnAllTagsWithRedHatCtx
        requires:
          - build
          - provision-cluster
    - provision-scale-cluster:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          # Build may take a while, so only run this after the build, so we can maximize the amount of time the tests may run.
          - build
    - scale-tests:
        <<: *runOnAllTagsWithRedHatCtx
        requires:
          - build
          - provision-scale-cluster
