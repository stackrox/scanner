#! circleci config validate
version: 2.1

defaultImage: &defaultImage
  image: "quay.io/rhacs-eng/apollo-ci:scanner-test-cci-0.3.41"
  auth:
    username: $QUAY_RHACS_ENG_RO_USERNAME
    password: $QUAY_RHACS_ENG_RO_PASSWORD

defaultWorkingDirectory: &defaultWorkingDirectory '/go/src/github.com/stackrox/scanner'

defaults: &defaults
  docker:
    - *defaultImage
  working_directory: /go/src/github.com/stackrox/scanner

runOnAllTags: &runOnAllTags
  filters:
    tags:
      only: /.*/

runOnAllTagsWithQuayPullCtx: &runOnAllTagsWithQuayPullCtx
  <<: *runOnAllTags
  context: quay-rhacs-eng-readonly

runOnAllTagsWithRedHatCtx: &runOnAllTagsWithRedHatCtx
  <<: *runOnAllTags
  context:
  - redhat-developer-account-login
  - quay-rhacs-eng-readonly

# https://circleci.com/developer/orbs/orb/circleci/slack
orbs:
  slack: circleci/slack@4.4.2
  ci-artifacts: stackrox/ci-artifacts-orb@0.0.11

slackTemplateTestFailure: &slackTemplateTestFailure
  custom: |
     {
       "text": "CircleCI job failed.",
       "blocks": [
         {
           "type": "header",
           "text": {
             "type": "plain_text",
             "text": "Job Failed. :red_circle:",
             "emoji": true
           }
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Job*: ${CIRCLE_JOB}"
             }
           ]
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Project*: $CIRCLE_PROJECT_REPONAME"
             },
             {
               "type": "mrkdwn",
               "text": "*Branch*: $CIRCLE_BRANCH"
             }
           ]
         },
         {
           "type": "section",
           "fields": [
             {
               "type": "mrkdwn",
               "text": "*Mentions*: $SLACK_PARAM_MENTIONS"
             }
           ]
         },
         {
           "type": "actions",
           "elements": [
             {
               "type": "button",
               "text": {
                 "type": "plain_text",
                 "text": "View Job"
               },
               "url": "${CIRCLE_BUILD_URL}"
             }
           ]
         }
       ]
     }

commands:
  check-on-master-or-tag:
    description: Run on master or tags only
    steps:
      - run:
          name: Determine whether to run step
          command: |
            if [[ "${CIRCLE_BRANCH}" == "master" || -n "${CIRCLE_TAG}" ]]; then
              echo "On master or tag, running the step"
            else
              echo "Not on master or tag, halting step"
              circleci step halt
            fi

  check-label-to-run:
    description: Run on master, but skip on PRs and tags unless the given label is provided
    parameters:
      label:
        type: string
      runOnMaster:
        type: boolean
        default: true
      runOnTag:
        type: boolean
        default: false
    steps:
      - run:
          name: Determine whether to run step
          command: |
            set +e
            if [[ "<< parameters.runOnMaster >>" == "true" && "${CIRCLE_BRANCH}" == "master" ]]; then
              echo "On master, running the step"
              exit 0
            fi

            if [[ "<< parameters.runOnTag >>" == "true" && -n "${CIRCLE_TAG}" ]]; then
              echo "On tag ${CIRCLE_TAG}, running the step"
              exit 0
            fi

            if [[ "${CIRCLE_BRANCH}" == "master" ]]; then
              echo "On master, but not running the step"
              circleci step halt
            fi

            .circleci/pr_has_label.sh "<< parameters.label >>"
            if [[ $? -eq 1 ]]; then
              echo "Skipping tests because we're on a PR. Apply the << parameters.label >> label to your PR if you want to run them."
              circleci step halt
            else
              echo "PR has label << parameters.label >>, running this step"
            fi

  wait-for-scanner-and-pf:
    description: Wait for the scanner pod to meet the given condition, and port-forward
    parameters:
      condition:
        type: string
      sleep-after-condition-met:
        type: integer
        default: 0
    steps:
      - run:
          name: Wait for the pod to be << parameters.condition >>, and port-forward
          command: |
            sleep 5
            kubectl -n stackrox get pod
            POD="$(kubectl -n stackrox get pod -o jsonpath='{.items[?(@.metadata.labels.app=="scanner")].metadata.name}')"
            [[ -n "${POD}" ]]
            kubectl -n stackrox wait "--for=condition=<< parameters.condition >>" "pod/${POD}" --timeout=3m
            sleep << parameters.sleep-after-condition-met >>
            kubectl -n stackrox get pod

            success=0
            for i in $(seq 1 10); do
              nohup kubectl port-forward -n stackrox "${POD}" "8080:8080" & # Legacy clairify endpoint
              nohup kubectl port-forward -n stackrox "${POD}" "8443:8443" & # gRPC endpoint
              curl --retry 12 --retry-connrefused -4 --retry-delay 5 --retry-max-time 60 -sk 'https://localhost:8080/clairify/ping' || touch FAIL
              curl --retry 12 --retry-connrefused -4 --retry-delay 5 --retry-max-time 60 -skf 'https://localhost:8443/v1/ping' || touch FAIL
              if [[ ! -f FAIL ]]; then
                success=1
                break
              fi
              echo "Port-forwarding failed."
              cat nohup.out || true
              rm nohup.out || true
              rm FAIL || true
              pkill kubectl || true
              sleep 5
            done

            [[ "${success}" -gt 0 ]]

  scanner-db-pf:
    description: Port-forward the scanner db
    steps:
      - run:
          name: Port-forward
          command: |
            sleep 5
            kubectl -n stackrox get pod
            POD="$(kubectl -n stackrox get pod -o jsonpath='{.items[?(@.metadata.labels.app=="scanner-db")].metadata.name}')"
            [[ -n "${POD}" ]]
            kubectl -n stackrox wait "--for=condition=Ready" "pod/${POD}" --timeout=10m
            nohup kubectl port-forward -n stackrox "${POD}" "5432:5432" & # PostgreSQL endpoint.
            sleep 10

  setup-gcp:
    description: Set up GCP service account and configure gcloud
    parameters:
      service-account-env:
        type: string
        default: GOOGLE_SA_CIRCLECI_SCANNER
    steps:
      - run:
          name: Configure GCP service account and gcloud
          command: |
            cci-export GOOGLE_APPLICATION_CREDENTIALS /tmp/gcp.json
            echo "${<< parameters.service-account-env >>}" > "${GOOGLE_APPLICATION_CREDENTIALS}"
            chmod 0600 "${GOOGLE_APPLICATION_CREDENTIALS}"
            gcloud auth activate-service-account --key-file "${GOOGLE_APPLICATION_CREDENTIALS}"
            gcloud auth list
            gcloud auth configure-docker
            gcloud config set project stackrox-ci
            gcloud config set core/disable_prompts True

  create-gke:
    parameters:
      wait:
        type: boolean
        default: true

    steps:
      - run:
          name: Create GKE cluster
          command: |
            source .circleci/create-cluster.sh && create-cluster
            <<# parameters.wait >>
            wait-for-cluster
            <</ parameters.wait >>

  teardown-gke:
    steps:
      - run:
          name: Tear down GKE cluster
          command: |
            [[ -n "$CLUSTER_NAME" ]]
            gcloud container clusters delete "$CLUSTER_NAME" --async

          when: always

  provision-gke-cluster:
    parameters:
      cluster-id:
        type: string
      num-nodes:
        type: integer
        default: 1

    steps:
      - setup-gcp
      - run:
          name: Assign environment variables
          command: |
            CLUSTER_NAME="stackrox-scanner-ci-<< parameters.cluster-id >>-${CIRCLE_BUILD_NUM}"
            cci-export CLUSTER_NAME "$CLUSTER_NAME"
            echo "Assigned cluster name is $CLUSTER_NAME"

            NUM_NODES="<< parameters.num-nodes >>"
            cci-export NUM_NODES "$NUM_NODES"
            echo "Number of nodes for cluster is $NUM_NODES"

      - create-gke:
          wait: false

      - run:
          name: Save cluster config
          command: |
            CONFIG_DIR="/tmp/.ci-clusters/<< parameters.cluster-id >>"
            mkdir -p "$CONFIG_DIR"
            echo "$CLUSTER_NAME" >>"${CONFIG_DIR}/name"
            gcloud config get-value compute/zone >>"${CONFIG_DIR}/zone"

      - run:
          name: Tear down cluster upon failure
          command: |
            gcloud container clusters delete "$CLUSTER_NAME" --async
          when: on_fail

      - persist_to_workspace:
          root: /tmp
          paths:
            - .ci-clusters/<< parameters.cluster-id >>

  attach-gke-cluster:
    parameters:
      cluster-id:
        type: string

    steps:
      - run:
          name: Restore config for << parameters.cluster-id >> cluster
          command: |
            CONFIG_DIR="/tmp/.ci-clusters/<< parameters.cluster-id >>"
            CLUSTER_NAME="$(cat "${CONFIG_DIR}/name")"
            [[ -n "$CLUSTER_NAME" ]]
            ZONE="$(cat "${CONFIG_DIR}/zone")"
            [[ -n "$ZONE" ]]
            gcloud config set compute/zone "$ZONE"
            cmd=(gcloud container clusters get-credentials --project stackrox-ci --zone "$ZONE" "$CLUSTER_NAME")
            "${cmd[@]}"
            echo "Restored config for cluster ${CLUSTER_NAME}"
            cci-export CLUSTER_NAME "$CLUSTER_NAME"
            echo
            echo "Run the following command to attach to the cluster:"
            echo
            printf " %q" "${cmd[@]}"
            echo

  build-and-push-image:
    parameters:
      make-image-target:
        type: string

    steps:
      - checkout
      - setup_remote_docker
      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Pull definitions dumps
          command: |
            if .circleci/pr_has_label.sh "generate-dumps-on-pr"; [[ $? -eq 1 ]]; then
              echo "Label generate-dumps-on-pr not set. Pulling dumps from GCS bucket"
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/pg-definitions.sql.gz image/db/dump/definitions.sql.gz
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/nvd-definitions.zip /tmp/nvd-definitions.zip
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/k8s-definitions.zip /tmp/k8s-definitions.zip
              gsutil cp gs://stackrox-scanner-ci-vuln-dump/repo2cpe.zip /tmp/repo2cpe.zip
            else
              cp /tmp/postgres/pg-definitions.sql.gz image/db/dump/definitions.sql.gz
              zip /tmp/genesis-dump/dump.zip 'nvd/*' --copy --out /tmp/nvd-definitions.zip
              zip /tmp/genesis-dump/dump.zip 'k8s/*' --copy --out /tmp/k8s-definitions.zip
              zip /tmp/genesis-dump/dump.zip 'rhelv2/repository-to-cpe.json' --copy --out /tmp/repo2cpe.zip
            fi

            unzip -d image/scanner/dump /tmp/nvd-definitions.zip
            unzip -d image/scanner/dump /tmp/k8s-definitions.zip
            unzip -d image/scanner/dump /tmp/repo2cpe.zip

      - run:
          name: Build images
          command: make << parameters.make-image-target >>

      - run:
          name: Ensure image is not dirty
          command: git diff --exit-code HEAD

      - run:
          name: Push images
          command: |
            source scripts/ci/lib.sh
            push_images "${CIRCLE_TAG:-}"

  run-e2e-tests:
    parameters:
      is-slim:
        type: boolean
      cluster-id:
        type: string

    steps:
      - checkout
      - setup_remote_docker
      - setup-gcp

      - attach_workspace:
          at: /tmp

      - attach-gke-cluster:
          cluster-id: << parameters.cluster-id >>

      - run:
          name: Deploy into the cluster
          command: |
            if [[ "<< parameters.is-slim >>" == "true" ]]; then
              make slim-deploy
            else
              make deploy
            fi

      - wait-for-scanner-and-pf:
          condition: Ready

      - run:
          name: Run sanity tests
          no_output_timeout: 20m
          command: |
            if [[ "<< parameters.is-slim >>" == "true" ]]; then
              make slim-e2e-tests
            else
              make e2e-tests
            fi

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - fetch-and-upload-scanner-metrics

      - ci-artifacts/store:
          path: /tmp/k8s-service-logs
          destination: k8s-service-logs-<< parameters.cluster-id >>

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - run:
          name: Verify that StackRox service logs contain no suspicious entries
          command: |
            if [[ ! -d "/tmp/k8s-service-logs/stackrox" ]]; then
              echo >&2 "StackRox logs were not collected. (Use collect: true or collectK8sLogs.)"
              exit 1
            fi
            logs=$(ls /tmp/k8s-service-logs/stackrox/*.log)
            filtered=$(ls ${logs} | grep -v "previous.log" || true)
            if [[ -n "${filtered}" ]]; then
                if ! scripts/ci/logcheck/check.sh ${filtered}; then
                    echo >&2 "Found at least one suspicious log file entry."
                    exit 1
                fi
            fi
          when: always

      - teardown-gke

  run-scale-tests:
    parameters:
      cluster-id:
        type: string

    steps:
      - checkout
      - check-label-to-run:
          label: scale-tests
          runOnMaster: false
          runOnTag: true
      - setup_remote_docker
      - setup-gcp

      - attach_workspace:
          at: /tmp

      - attach-gke-cluster:
          cluster-id: << parameters.cluster-id >>

      - run:
          name: Deploy into the cluster
          command: |
            cci-export LOGLEVEL "INFO"
            make deploy

      - wait-for-scanner-and-pf:
          condition: Ready

      - run:
          name: Run scale tests and collect profile
          no_output_timeout: 20m
          command: make scale-tests

      - ci-artifacts/store:
          path: /tmp/pprof.zip
          destination: pprof.zip

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - fetch-and-upload-scanner-metrics

      - run:
          name: Collect k8s logs
          command: |
            .circleci/collect-service-logs.sh stackrox
            .circleci/collect-service-logs.sh kube-system
          when: always

      - ci-artifacts/store:
          path: /tmp/k8s-service-logs
          destination: k8s-service-logs-<< parameters.cluster-id >>

      - run:
          name: Verify the scanner did not restart
          command: |
            if [[ "$(ls /tmp/k8s-service-logs/stackrox/*-previous.log | wc -l)" != 0 ]]; then
                ls /tmp/k8s-service-logs/stackrox/*-previous.log
                exit 1
            fi
            cat nohup.out || true
          when: always

      - run:
          name: Verify that StackRox service logs contain no suspicious entries
          command: |
            if [[ ! -d "/tmp/k8s-service-logs/stackrox" ]]; then
              echo >&2 "StackRox logs were not collected. (Use collect: true or collectK8sLogs.)"
              exit 1
            fi
            logs=$(ls /tmp/k8s-service-logs/stackrox/*.log)
            filtered=$(ls ${logs} | grep -v "previous.log" || true)
            if [[ -n "${filtered}" ]]; then
                if ! scripts/ci/logcheck/check.sh ${filtered}; then
                    echo >&2 "Found at least one suspicious log file entry."
                    exit 1
                fi
            fi
          when: always

      - teardown-gke

  fetch-and-upload-scanner-metrics:
    steps:
      - run:
          name: Portforward and curl scanner metrics
          command: |
            kubectl -n stackrox port-forward deploy/scanner 9090:9090 1>/dev/null 2>&1 &
            sleep 5
            mkdir -p /tmp/metrics
            curl localhost:9090/metrics > /tmp/metrics/metrics.prom
      - ci-artifacts/store:
          path: /tmp/metrics
          destination: metrics

jobs:
  unit-tests:
    <<: *defaults
    steps:
      - checkout

      - run:
          name: Install dependencies
          command: make deps

      - run:
          name: Run unit tests
          command: make unit-tests

  style-checks:
    <<: *defaults
    steps:
      - checkout

      - run:
          name: Install dependencies
          command: make deps

      - run:
          name: Run style checks
          command: make style

  db-integration-tests:
    docker:
      - *defaultImage
      - image: postgres:12-bullseye
        environment:
          POSTGRES_PASSWORD: password
    working_directory: *defaultWorkingDirectory
    steps:
      - checkout
      - run:
          name: Install dependencies
          command: make deps
      - run:
          name: Run db integration tests (slim tests are a subset of the full tests)
          command: make db-integration-tests

  generate-genesis-dump:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true
      - run:
          name: Build updater, and persist to workspace
          command: |
            make build-updater
            mkdir -p /tmp/updater-bin
            cp ./bin/updater /tmp/updater-bin/

      - run:
          name: Generate the genesis dump
          command: |
            mkdir -p /tmp/genesis-dump
            ./bin/updater generate-dump --out-file /tmp/genesis-dump/dump.zip
            ls -lrt /tmp/genesis-dump

      - run:
          name: Print some stats
          command: |
            ./bin/updater print-stats /tmp/genesis-dump/dump.zip

      - ci-artifacts/store:
          path: /tmp/genesis-dump/dump.zip
          destination: genesis-dump.zip

      - persist_to_workspace:
          root: /tmp
          paths:
            - genesis-dump
            - updater-bin

  create-postgres-dump-from-genesis-dump:
    docker:
      - *defaultImage
      - image: postgres:12-bullseye
        environment:
          POSTGRES_HOST_AUTH_METHOD: scram-sha-256
          POSTGRES_PASSWORD: password
          POSTGRES_INITDB_ARGS: --auth=scram-sha-256
    working_directory: *defaultWorkingDirectory
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true
      - setup_remote_docker
      - attach_workspace:
          at: /tmp

      - run:
          name: Restore updater bin
          command: |
            cp /tmp/updater-bin/updater ./bin/

      - run:
          name: Load vuln contents into postgres
          command: |
            ./bin/updater load-dump --postgres-host 127.0.0.1 --postgres-port 5432 --dump-file /tmp/genesis-dump/dump.zip

      - run:
          name: Take a PG dump
          command: |
            mkdir /tmp/postgres
            pg_dump -U postgres postgres://127.0.0.1:5432 > /tmp/postgres/pg-definitions.sql
            gzip --best /tmp/postgres/pg-definitions.sql

      - ci-artifacts/store:
          path: /tmp/postgres/pg-definitions.sql.gz
          destination: pg-definitions.sql.gz

      - persist_to_workspace:
          root: /tmp
          paths:
            - postgres

      - check-on-master-or-tag
      - setup-gcp
      - run:
          name: Upload PG dump to Google Storage
          command: |
            echo "On master or tag, uploading pg dump result to GCS"
            gsutil cp /tmp/postgres/pg-definitions.sql.gz gs://stackrox-scanner-ci-vuln-dump

  upload-dumps-for-embedding-into-image:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true

      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Generate dumps
          command: |
            mkdir -p /tmp/vuln-dump
            zip /tmp/genesis-dump/dump.zip 'nvd/*' --copy --out /tmp/vuln-dump/nvd-definitions.zip
            zip /tmp/genesis-dump/dump.zip 'k8s/*' --copy --out /tmp/vuln-dump/k8s-definitions.zip
            zip /tmp/genesis-dump/dump.zip 'rhelv2/repository-to-cpe.json' --copy --out /tmp/vuln-dump/repo2cpe.zip

      - persist_to_workspace:
          root: /tmp
          paths:
            - vuln-dump

      - run:
          name: Upload to Google Storage
          command: |
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/nvd-definitions.zip gs://stackrox-scanner-ci-vuln-dump
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/k8s-definitions.zip gs://stackrox-scanner-ci-vuln-dump
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/repo2cpe.zip gs://stackrox-scanner-ci-vuln-dump

  # Copy definitions files to be available in the publicly-accessible bucket for embedding in the downstream builds on
  # the Red Hat infrastructure. See usage in distgit/containers/rhacs-scanner/pre-build-script
  # and in distgit/containers/rhacs-scanner-db/pre-build-script
  # in branches of https://code.engineering.redhat.com/gerrit/gitweb?p=rhacs.git;a=summary
  upload-dumps-for-downstream-builds:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: true
      - setup-gcp:
          service-account-env: GOOGLE_SA_STACKROX_HUB_VULN_DUMP_UPLOADER
      - attach_workspace:
          at: /tmp
      - run:
          name: Upload dumps to Google Storage
          command: |
            set -x

            if [[ -n "${CIRCLE_TAG}" || "${CIRCLE_BRANCH}" != "master" ]]; then
              # Tagged builds are the main ones for which we push artifacts and we use the tag as label. Makefile will
              # return tag in the `2.20.0` format for them.

              # Also, for PRs with the expected label, we will use the tag that the makefile returns. However that tag
              # would look like `2.20.0-3-g74ff9abf69` and should not overwrite the production tagged dumps. This is
              # enabled for ability to dry-run this upload job.

              scanner_version="$(make --quiet --no-print-directory tag)"
            else
              # For the master branch we store artifacts in "unversioned" way to make sure this upload job works and
              # does not break on more rare tagged builds. Note that we should not consume these latest builds
              # downstream, we should use tagged ones instead becase otherwise the master branch can introduce format
              # changes that the downstream release can be unprepared to deal with.
              scanner_version="latest"
            fi
            destination="gs://definitions.stackrox.io/scanner-data/${scanner_version}/"

            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
              cmd+=(echo "Would do")
            fi

            "${cmd[@]}" gsutil cp /tmp/vuln-dump/nvd-definitions.zip "$destination"
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/k8s-definitions.zip "$destination"
            "${cmd[@]}" gsutil cp /tmp/vuln-dump/repo2cpe.zip "$destination"
            "${cmd[@]}" gsutil cp /tmp/postgres/pg-definitions.sql.gz "$destination"
            # Note that we include genesis manifests for the downstream to avoid the situation when dumps taken from
            # GCloud are older than manifests taken from the source code repo.
            "${cmd[@]}" gsutil cp image/scanner/dump/genesis_manifests.json "$destination"

  create-diff-dumps:
    <<: *defaults
    resource_class: large
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: false
      - setup-gcp
      - attach_workspace:
          at: /tmp

      - run:
          name: Restore updater bin
          command: |
            cp /tmp/updater-bin/updater ./bin/

      - run:
          name: Create diff for each manifest
          command: |
            mkdir -p /tmp/diff-dumps
            idx=-1
            while IFS=$'\t' read -r dumploc timestamp config; do
              idx=$((idx+1))
              dump_file_name="${dumploc##*/}"
              echo "Pulling genesis dump from ${dumploc}"
              gsutil cp "${dumploc}" .
              timestamp_in_zip="$(unzip -p "${dump_file_name}" manifest.json | jq -r '.until')"
              echo "Got timestamps -- from zip: ${timestamp_in_zip}; from manifest: ${timestamp}"
              [[ "${timestamp_in_zip}" == "${timestamp}" ]] # Assertion on the manifest contents
              ./bin/updater diff-dumps --base-dump "${dump_file_name}" --head-dump /tmp/genesis-dump/dump.zip --config "${config}" --out-file "/tmp/diff-dumps/dump${idx}/diff.zip"
            done < <(jq -r '.knownGenesisDumps | .[]| [.dumpLocationInGS, .timestamp, (.config // empty | tostring)] | @tsv' < image/scanner/dump/genesis_manifests.json)
            du -d 2 -kh "/tmp/diff-dumps"

      - persist_to_workspace:
          root: /tmp
          paths:
            - diff-dumps

      - ci-artifacts/store:
          path: /tmp/diff-dumps

  upload-diff-dumps-and-offline-dumps:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: generate-dumps-on-pr
          runOnTag: false
      - setup-gcp:
          service-account-env: GOOGLE_SA_STACKROX_HUB_VULN_DUMP_UPLOADER
      - attach_workspace:
          at: /tmp

      - run:
          name: Upload each diff dump to the prod bucket
          command: |
            idx=-1
            while IFS=$'\t' read -r diffUUID; do
              idx=$((idx+1))
              expected_zip_file_loc="/tmp/diff-dumps/dump${idx}/diff.zip"
              [[ -f "${expected_zip_file_loc}" ]]
              if [[ -z "${diffUUID}" ]]; then
                continue
              fi
              echo "Found file at ${expected_zip_file_loc}"
              du -skh "${expected_zip_file_loc}"
              cmd=()
              if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
                cmd+=(echo "Would do")
              fi
              "${cmd[@]}" gsutil cp "${expected_zip_file_loc}" gs://definitions.stackrox.io/"${diffUUID}"/diff.zip
            done < <(jq -r '.knownGenesisDumps | .[]| [.uuid] | @tsv' < image/scanner/dump/genesis_manifests.json)

      - run:
          name: Generate offline dump
          command: |
            mkdir -p /tmp/offline-dump

            # Fetch the scanner dump which is marked as the base for offline dumps.
            # For offline dumps, we just use one base (the oldest base which is in a version of scanner still supported)
            # for simplicity.
            offline_dumps="$(jq '.knownGenesisDumps | map(.baseForOfflineDumps == true) | indices(true)' < image/scanner/dump/genesis_manifests.json)"
            echo "Got offline dumps list: ${offline_dumps}"
            [[ "$(echo "${offline_dumps}" | jq 'length')" -eq 1 ]]
            offline_diff_location="/tmp/diff-dumps/dump$(echo "${offline_dumps}" | jq -r '.[0]')/diff.zip"
            cp "${offline_diff_location}" /tmp/offline-dump/scanner-defs.zip

            # Prepare k8s and istio dump
            mkdir -p /tmp/scratch
            gsutil cp -r gs://definitions.stackrox.io/cve/* /tmp/scratch/
            cd /tmp/scratch
            zip -r /tmp/offline-dump/k8s-istio.zip *

            cd /tmp/offline-dump
            zip scanner-vuln-updates.zip scanner-defs.zip k8s-istio.zip
            du -skh scanner-vuln-updates.zip
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp scanner-vuln-updates.zip gs://sr-roxc/scanner/scanner-vuln-updates.zip

      - setup-gcp:
          service-account-env: GCP_SERVICE_ACCOUNT_CREDS

      - run:
          name: Push offline dump to a public bucket
          command: |
            cd /tmp/offline-dump
            cmd=()
            if [[ "${CIRCLE_BRANCH}" != "master" && -z "${CIRCLE_TAG}" ]]; then
              cmd+=(echo "Would do")
            fi
            "${cmd[@]}" gsutil cp scanner-vuln-updates.zip gs://scanner-support-public/offline/v1/scanner-vuln-updates.zip

  build:
    <<: *defaults
    steps:
      - build-and-push-image:
          make-image-target: all-images

  provision-cluster:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - provision-gke-cluster:
          cluster-id: rhel

  provision-slim-cluster:
    <<: *defaults
    steps:
      - checkout
      - setup_remote_docker
      - provision-gke-cluster:
          cluster-id: rhel-slim

  provision-scale-cluster:
    <<: *defaults
    steps:
      - checkout
      - check-label-to-run:
          label: scale-tests
          runOnMaster: false
          runOnTag: true
      - setup_remote_docker
      - provision-gke-cluster:
          cluster-id: rhel-scale

  e2e-tests:
    <<: *defaults
    steps:
      - run-e2e-tests:
          is-slim: false
          cluster-id: rhel

  slim-e2e-tests:
    <<: *defaults
    steps:
      - run-e2e-tests:
          is-slim: true
          cluster-id: rhel-slim

  scale-tests:
    <<: *defaults
    steps:
      - run-scale-tests:
          cluster-id: rhel-scale

  sanity-check-vuln-updates:
    <<: *defaults
    steps:
      - checkout
      - setup-gcp:
          service-account-env: GOOGLE_SA_STACKROX_HUB_VULN_DUMP_UPLOADER
      - run:
          name: Check scanner vulnerability updates
          command: ./tests/sanity-check-vuln-updates.sh
      - ci-artifacts/store:
          path: /tmp/ROX-7271
      - slack/notify:
          branch_pattern: master
          channel: oncall
          event: fail
          ignore_errors: false
          mentions: "@scanner-defs-oncall,@shane"
          <<: *slackTemplateTestFailure

  trigger-nightly-build:
    <<: *defaults
    resource_class: small
    steps:
      - checkout
      - run:
          name: Configure git
          command: |
            git config user.email "roxbot@stackrox.com"
            git config user.name "RoxBot"
      - add_ssh_keys:
          fingerprints:
            - "b0:90:e9:6f:77:d5:fe:b6:8c:1a:a5:3f:a4:e3:41:e5"
      - run:
          name: Add SSH key of github.com
          command: |
            ssh-keyscan -H github.com >> ~/.ssh/known_hosts
      - run:
          name: Create a commit and tag for nightly build
          command: |
            # Add an empty commit to diverge from master
            git commit --allow-empty -m "Nightly build $(date)"
            NIGHTLY_TAG="$(git describe --tags --abbrev=0 --exclude '*-nightly-*')-nightly-$(date '+%Y%m%d')"
            git tag "$NIGHTLY_TAG"
            git push origin "$NIGHTLY_TAG"
      - run:
          name: Remove tags more than 3 days old
          command: |
            beforeDate=$(date --date=@$(($(date +'%s') - (3 * 24 * 60 * 60))) +'%Y%m%d')
            echo "Anything prior to ${beforeDate} will be deleted"
            tags=$(git tag --list '*nightly*')
            for tag in $tags; do
                echo "Considering nightly tag: ${tag}"
                datePart="${tag##*-}"
                echo "  date part: ${datePart}"
                if [[ "${datePart}" =~ ^-?[0-9]+$ ]] && [ "${datePart}" -lt ${beforeDate} ]; then
                    echo "  this tag is a candidate for deletion"
                    git push --delete origin "${tag}"
                else
                    echo "  this tag is not a candidate for deletion"
                fi
            done

workflows:
  version: 2

  update-dumps-hourly:
    triggers:
      - schedule:
          cron: "0 * * * *"
          filters:
            branches:
              only: master

    jobs:
      - generate-genesis-dump:
          <<: *runOnAllTagsWithQuayPullCtx
      - create-postgres-dump-from-genesis-dump:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - create-diff-dumps:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - upload-dumps-for-embedding-into-image:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - generate-genesis-dump
      - upload-diff-dumps-and-offline-dumps:
          <<: *runOnAllTags
          context:
            - quay-rhacs-eng-readonly
            - scanner-support
          requires:
            - create-diff-dumps
      - upload-dumps-for-downstream-builds:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - create-postgres-dump-from-genesis-dump
            - upload-dumps-for-embedding-into-image
      - unit-tests:
          <<: *runOnAllTagsWithQuayPullCtx
      - style-checks:
          <<: *runOnAllTagsWithQuayPullCtx
      - db-integration-tests:
          <<: *runOnAllTagsWithQuayPullCtx
      - build:
          <<: *runOnAllTags
          context:
            - docker-io-and-stackrox-io-push
            - quay-rhacs-eng-readwrite
            - quay-rhacs-eng-readonly
            - quay-stackrox-io-readwrite
          requires:
            - create-postgres-dump-from-genesis-dump
            - upload-dumps-for-embedding-into-image
      - provision-cluster:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - create-postgres-dump-from-genesis-dump
      - e2e-tests:
          <<: *runOnAllTagsWithRedHatCtx
          requires:
            - build
            - provision-cluster
      - provision-slim-cluster:
          <<: *runOnAllTagsWithQuayPullCtx
          requires:
            - create-postgres-dump-from-genesis-dump
      - slim-e2e-tests:
          <<: *runOnAllTagsWithRedHatCtx
          requires:
            - build
            - provision-slim-cluster

  sanity-check-vuln-updates-scheduled:
    triggers:
      - schedule:
          cron: "5 0,4,8,12,16,20 * * *"
          filters:
            branches:
              only:
                - master
    jobs:
      - sanity-check-vuln-updates:
          context:
          - quay-rhacs-eng-readonly
          - com-slack-srox

  build:
    jobs:
    - generate-genesis-dump:
        <<: *runOnAllTagsWithQuayPullCtx
    - create-postgres-dump-from-genesis-dump:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - create-diff-dumps:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - upload-dumps-for-embedding-into-image:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - generate-genesis-dump
    - upload-diff-dumps-and-offline-dumps:
        <<: *runOnAllTags
        context:
          - quay-rhacs-eng-readonly
          - scanner-support
        requires:
          - create-diff-dumps
    - upload-dumps-for-downstream-builds:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - create-postgres-dump-from-genesis-dump
          - upload-dumps-for-embedding-into-image
    - unit-tests:
        <<: *runOnAllTagsWithQuayPullCtx
    - style-checks:
        <<: *runOnAllTagsWithQuayPullCtx
    - db-integration-tests:
        <<: *runOnAllTagsWithQuayPullCtx
    - build:
        <<: *runOnAllTags
        context:
          - docker-io-and-stackrox-io-push
          - quay-rhacs-eng-readonly
          - quay-rhacs-eng-readwrite
          - quay-stackrox-io-readwrite
        requires:
          - create-postgres-dump-from-genesis-dump
          - upload-dumps-for-embedding-into-image
    - provision-cluster:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - create-postgres-dump-from-genesis-dump
    - e2e-tests:
        <<: *runOnAllTagsWithRedHatCtx
        requires:
          - build
          - provision-cluster
    - provision-slim-cluster:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          - create-postgres-dump-from-genesis-dump
    - slim-e2e-tests:
        <<: *runOnAllTagsWithRedHatCtx
        requires:
          - build
          - provision-slim-cluster
    - provision-scale-cluster:
        <<: *runOnAllTagsWithQuayPullCtx
        requires:
          # Build may take a while, so only run this after the build, so we can maximize the amount of time the tests may run.
          - build
    - scale-tests:
        <<: *runOnAllTagsWithRedHatCtx
        requires:
          - build
          - provision-scale-cluster

  nightly:
    triggers:
      - schedule:
          cron: "18 11 * * *"
          filters:
            branches:
              only: master
    jobs:
      - trigger-nightly-build:
          filters:
            branches:
              only: master
          context: quay-rhacs-eng-readonly
